## house-price-predict
# 记第一次参加数据预测相关的竞赛

比赛链接如下http://www.pkbigdata.com/common/cmpt/%E4%BD%8F%E6%88%BF%E6%9C%88%E7%A7%9F%E9%87%91%E9%A2%84%E6%B5%8B%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%B5%9B%EF%BC%88%E4%BB%98%E8%B4%B9%E7%AB%9E%E8%B5%9B%EF%BC%89_%E7%AB%9E%E8%B5%9B%E4%BF%A1%E6%81%AF.html

简单描述一下，是一个租金预测的比赛，给了前三个月共上万条拥有十几条特征的数据，预测第四个月的租金，最终成绩按均方差排名。
最终，我们的队伍获得了29名（二等奖 共360个队伍）

最终代码可以分成三个部分（虽然过程中有很多失败的尝试，但是的完成体还是比较简短的）：

#  数据处理
由于数据中只有一个字符类型变量，是房屋朝向，我们并没有选用one-hot处理，而是照各个类型变量的不同取值对应的样本集内房价的均值，按照房价均值高低对此变量的当前取值确定其相对数值1,2,3,4等等，相当于对类型变量赋值使其成为连续变量。此方法采用了与One-Hot编码不同的方法来处理离散数据，值得学习。由于接下来我们选用的都是树模型，所以以数值作为标志的离散变量不需要onehot处理  第二个点就是缺省值处理，train和test的数据缺省的程度较好 大部分缺省都是按零处理，只有少量的数据是真正的缺失 所以我直接按平均值处理 效果似乎不错。  

#  数据特征组合和模型调参
__这一部分很失败 __ 这涉及到我们组遇到的第一个瓶颈  __没有很好的数据划分方法__ 
最初是用的xgb原生库自带的cv函数fold=5做交叉验证 然而在depth和min_child_weight的调优上  预测集上分数好的反而在最终提交后分数不高 并且预测集的结果和实际分数差距很大，应该是过拟合导致
当时在这一块折腾了很久 最后真的是身心俱疲。。以至于后面xgb的参数并没有调 也不知道特征组合对于预测模型是否会有提升 只是用低学习率和高迭代次数草草了事

感谢赛后第一名开放了代码 他们使用的是那前两个月做训练 预测集为第三个月 调优后线上线下分数差距很小，后来才意识到预测划分的重要性，预测集越接近测试集分布越好，因为调优的最终评判完全是按照预测集的成绩，所以预测集的划分将直接决定模型的好坏。

#  模型融合
感谢队友后来发现了一个比xgb速度快效果好的模型 ExtraTreesRegressor 一开始我是在xgb一棵树上吊死了 因为坚信xgb是数据预测的神器，后来才知道模型不能只局限于一种，多种模型横向比较 再赋予不同的权值融合训练 效果往往比单个模型要好 特别是两种模型成绩相近的情况。

