{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orientation_E'] \n",
      "1 qualitative attributes have been encoded.\n"
     ]
    }
   ],
   "source": [
    "file= './train.csv'\n",
    "train=pd.read_csv(file)\n",
    "file1='./test.csv'\n",
    "test1=pd.read_csv(file1)\n",
    "train.rename(columns={'时间':'time', '小区名':'community', '小区房屋出租数量':'house_num', '楼层':'floor', '总楼层':'total_floor', '房屋面积':'area', '房屋朝向':'orientation', '居住状态':'status', '卧室数量':'bedroom_num',\n",
    "       '厅的数量':'livingroom_num', '卫的数量':'bathroom_num', '出租方式':'method', '区':'Urban', '位置':'location', '地铁线路':'underground', '地铁站点':'underground_station', '距离':'distance', '装修情况':'Decoration', '月租金':'price'},inplace=True)\n",
    "test1.rename(columns={'时间':'time', '小区名':'community', '小区房屋出租数量':'house_num', '楼层':'floor', '总楼层':'total_floor', '房屋面积':'area', '房屋朝向':'orientation', '居住状态':'status', '卧室数量':'bedroom_num',\n",
    "       '厅的数量':'livingroom_num', '卫的数量':'bathroom_num', '出租方式':'method', '区':'Urban', '位置':'location', '地铁线路':'underground', '地铁站点':'underground_station', '距离':'distance', '装修情况':'Decoration', 'id':'id'},inplace=True)\n",
    "id1=test1.id\n",
    "test1= test1.drop(['id'],axis=1)\n",
    "quantity = [attr for attr in train.columns if train.dtypes[attr] != 'object']  # 数值变量集合\n",
    "quality = [attr for attr in train.columns if train.dtypes[attr] == 'object']  # 类型变量集合\n",
    "def encode(frame,test, feature):\n",
    "    '''\n",
    "    对所有类型变量，依照各个类型变量的不同取值对应的样本集内房价的均值，按照房价均值高低\n",
    "    对此变量的当前取值确定其相对数值1,2,3,4等等，相当于对类型变量赋值使其成为连续变量。\n",
    "    此方法采用了与One-Hot编码不同的方法来处理离散数据，值得学习\n",
    "    注意：此函数会直接在原frame的DataFrame内创建新的一列来存放feature编码后的值。\n",
    "    '''\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique()\n",
    "    ordering.index = ordering.val\n",
    "    ordering['price_mean'] = frame[[feature, 'price']].groupby(feature).mean()['price']\n",
    "    # 上述 groupby()操作可以将某一feature下同一取值的数据整个到一起，结合mean()可以直接得到该特征不同取值的房价均值\n",
    "    ordering = ordering.sort_values('price_mean')\n",
    "    ordering['order'] = range(1, ordering.shape[0]+1)\n",
    "    ordering = ordering['order'].to_dict()\n",
    "    for attr_v, score in ordering.items():\n",
    "        # e.g. qualitative[2]: {'Grvl': 1, 'MISSING': 3, 'Pave': 2}\n",
    "        frame.loc[frame[feature] == attr_v, feature+'_E'] = score\n",
    "        test1.loc[test1[feature] == attr_v, feature+'_E'] = score\n",
    "\n",
    "quality_encoded = []\n",
    "# 由于qualitative集合中包含了非数值型变量和伪数值型变量（多为评分、等级等，其取值为1,2,3,4等等）两类\n",
    "# 因此只需要对非数值型变量进行encode()处理。\n",
    "# 如果采用One-Hot编码，则整个qualitative的特征都要进行pd,get_dummies()处理\n",
    "for q in quality:\n",
    "    encode(train,test1, q)\n",
    "    quality_encoded.append(q+'_E')\n",
    "train.drop(quality, axis=1, inplace=True)\n",
    "test1.drop(quality, axis=1, inplace=True) # 离散变量已经有了编码后的新变量，因此删去原变量\n",
    "# df_tr.shape = (1460, 80)\n",
    "print(quality_encoded, '\\n{} qualitative attributes have been encoded.'.format(len(quality_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.fillna(0,inplace = True)\n",
    "#test1.fillna(1,inplace = True)\n",
    "                 \n",
    "for d in ['house_num','Urban','location']:\n",
    "    train[d].fillna(train[d].mean(), inplace=True)\n",
    "for d in ['status','Decoration','method','distance','underground','underground_station']:\n",
    "    train[d].fillna(0, inplace=True)\n",
    "    \n",
    "for d in ['house_num','Urban','location']:\n",
    "    test1[d].fillna(test1[d].mean(), inplace=True)\n",
    "for d in ['status','Decoration','method','distance','underground','underground_station']:\n",
    "    test1[d].fillna(0, inplace=True)\n",
    "test1['orientation_E'].fillna(test1['orientation_E'].mean(), inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr=ExtraTreesRegressor(max_depth=1000,min_samples_split=4, n_jobs = -1)\n",
    "xg=XGBRegressor(max_depth=6,n_estimators=19000,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = train.drop(['price'],axis=1)\n",
    "y_log = train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg = AverageWeight(mod = [etr,xg],weight=[0.6,0.4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AverageWeight(mod=[ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=1000,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=1, min_samples_split=4,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators='warn',...,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)],\n",
       "       weight=[0.6, 0.4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_avg.fit(X_scaled,y_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id      price\n",
      "0          1   4.379525\n",
      "1          2   5.960286\n",
      "2          3  12.768639\n",
      "3          4   5.534577\n",
      "4          5   4.991634\n",
      "5          6  10.937753\n",
      "6          7   9.281098\n",
      "7          8   3.871248\n",
      "8          9   8.759528\n",
      "9         10   6.007465\n",
      "10        11   5.453805\n",
      "11        12   9.290493\n",
      "12        13   3.851166\n",
      "13        14   7.313627\n",
      "14        15   7.186250\n",
      "15        16  10.938377\n",
      "16        17   6.718289\n",
      "17        18   5.578862\n",
      "18        19   7.775946\n",
      "19        20   5.455036\n",
      "20        21   4.134382\n",
      "21        22   6.072959\n",
      "22        23   7.284374\n",
      "23        24   6.007118\n",
      "24        25   7.819614\n",
      "25        26   4.927101\n",
      "26        27   4.539472\n",
      "27        28   2.579838\n",
      "28        29   7.799630\n",
      "29        30   2.975708\n",
      "...      ...        ...\n",
      "56249  57970   4.137321\n",
      "56250  57971   6.363210\n",
      "56251  57973   7.039272\n",
      "56252  57974   8.506850\n",
      "56253  57975   8.913214\n",
      "56254  57976  13.055045\n",
      "56255  57977   6.486172\n",
      "56256  57978   5.235909\n",
      "56257  57979   5.380841\n",
      "56258  57980   9.982292\n",
      "56259  57981   3.263237\n",
      "56260  57982   4.049828\n",
      "56261  57983   8.347123\n",
      "56262  57984   8.941100\n",
      "56263  57985   7.887594\n",
      "56264  57986   5.669424\n",
      "56265  57987   9.494972\n",
      "56266  57988   4.463785\n",
      "56267  57989   6.489136\n",
      "56268  57990   5.904993\n",
      "56269  57991   5.926043\n",
      "56270  57992   5.381277\n",
      "56271  57993   7.571322\n",
      "56272  57995   7.277375\n",
      "56273  57996   6.544106\n",
      "56274  57997   4.976473\n",
      "56275  57998  13.052036\n",
      "56276  57999   7.338534\n",
      "56277  58000  12.958156\n",
      "56278  58001   4.637441\n",
      "\n",
      "[56279 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "p=weight_avg.predict(test1)\n",
    "id1['price']=p\n",
    "\n",
    "sp = pd.DataFrame()\n",
    "sp['id']=id1\n",
    "sp.drop(sp.index[-1],inplace=True)\n",
    "sp['price']=p\n",
    "sp.to_csv('try.csv',index=False)\n",
    "d=pd.read_csv('try.csv')\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.24312394  5.76952462 12.13234295 ...  7.4339983  12.85186757\n",
      "  4.03735144]\n"
     ]
    }
   ],
   "source": [
    "etr_y_predict=etr.predict(test1)\n",
    "print(etr_y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross validation strategy\n",
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y_log,random_state=20,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7255012351732348"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#ExtraTreesRegressor  X_scaled, y_log\n",
    "etr=ExtraTreesRegressor(max_depth=None,min_samples_split=4, n_jobs = -1, random_state=20)\n",
    "etr.fit(X_train,y_train)\n",
    "#etr.fit(X_scaled,y_log)\n",
    "etr_y_predict=etr.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test,etr_y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
